{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "This notebook implements baseline solution for defects classification problem in manufactured\n",
    "steel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , Flatten \n",
    "from keras.layers import Conv2D, MaxPooling2D , ZeroPadding2D\n",
    "from keras.utils import to_categorical \n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to load and scale input image #\n",
    "def image_load(path):\n",
    "    img=image.load_img(path)\n",
    "    img=image.img_to_array(img)\n",
    "    img=img/255\n",
    "    return(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##define folder locations for train and test data##\n",
    "train_image_dir='E:/severstal/data/train_images/'\n",
    "test_image_dir='E:/severstal/data/test_images/'\n",
    "base_dir='E:/severstal/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read label file#\n",
    "df_label=pd.read_csv(base_dir+'train.csv')\n",
    "#split first column to seperate image file name and its class#\n",
    "df_label['class']=df_label['ImageId_ClassId'].apply(lambda x:x.split(\"_\")[1])\n",
    "df_label['fname']=df_label['ImageId_ClassId'].apply(lambda x:x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating seperate dfs for clean and image with at least one defect#\n",
    "image_with_labels=df_label[~pd.isnull(df_label['EncodedPixels'])]\n",
    "image_wo_defects=df_label[pd.isnull(df_label['EncodedPixels'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique filenames with defects\n",
    "fnames=image_with_labels.fname.unique()\n",
    "#concatenate defects classes per image#\n",
    "class_list=[image_with_labels[image_with_labels['fname']==fid]['class'].tolist() for fid in fnames]\n",
    "#create data frame with one row per image with defect @\n",
    "uniq_image_with_defects=pd.DataFrame({'image_file':fnames,'class_labels':class_list})\n",
    "#get unique clean image file names#\n",
    "clean_fnames=image_wo_defects[~image_wo_defects['fname'].isin(fnames)].fname.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create 5th class as clean image#\n",
    "a=[list('5') for clean_f in clean_fnames]\n",
    "clean_df=pd.DataFrame({'image_file':clean_fnames,'class_labels':a})\n",
    "#concat image with defects and clean image df #\n",
    "all_image_with_labels=pd.concat([uniq_image_with_defects,clean_df],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implement one hot encoding for multi labels#\n",
    "mlb=MultiLabelBinarizer()\n",
    "x=mlb.fit_transform(all_image_with_labels['class_labels'])\n",
    "all_image_labels=pd.DataFrame()\n",
    "all_image_labels=all_image_with_labels.join(pd.DataFrame(x,columns=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all images from train set#\n",
    "train_image_mat=[]\n",
    "\n",
    "for i in range(all_image_labels.shape[0]):\n",
    "    path=train_image_dir+str(all_image_labels.image_file[i])\n",
    "    train_image_mat.append(image_load(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create input and label data#\n",
    "#split train data into dev and test set# \n",
    "X=np.array(train_image_mat)\n",
    "Y=np.array(all_image_labels.drop(['class_labels','image_file'],axis=1))\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,random_state=42,test_size=0.1)\n",
    "X_valid,X_test,Y_valid,Y_test=train_test_split(X_test,Y_test,random_state=42,test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN model\n",
    "### model architecture defined using references from this blog and coursera material https://www.analyticsvidhya.com/blog/2019/04/build-first-multi-label-image-classification-model-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(ZeroPadding2D((2,2),input_shape=(256,1600,3)))\n",
    "model.add(Conv2D(filters=16,kernel_size=(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=32,kernel_size=(5,5),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64,kernel_size=(5,5),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5,activation=\"sigmoid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_1 (ZeroPaddin (None, 260, 1604, 3)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 258, 1602, 16)     448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 129, 801, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 129, 801, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 125, 797, 32)      12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 398, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 62, 398, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 58, 394, 64)       51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 29, 197, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 29, 197, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 365632)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               46801024  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 46,874,149\n",
      "Trainable params: 46,874,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train,Y_train,epochs=5,validation_data=(X_valid,Y_valid),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate predictions#\n",
    "Y_pred=model.predict(X_test)\n",
    "Y_pred=(Y_pred>0.5)\n",
    "print(accuracy_score(Y_pred,Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
